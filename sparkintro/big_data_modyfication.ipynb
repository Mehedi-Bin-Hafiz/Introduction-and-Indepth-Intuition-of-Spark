{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5eefe0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+-----+\n",
      "|    date|store|item|sales|\n",
      "+--------+-----+----+-----+\n",
      "|02/01/13|    1|   1|   11|\n",
      "|02/02/13|    1|   1|   21|\n",
      "|02/03/13|    1|   1|   15|\n",
      "|02/04/13|    1|   1|   14|\n",
      "|02/05/13|    1|   1|    9|\n",
      "|02/06/13|    1|   1|   10|\n",
      "|02/07/13|    1|   1|   13|\n",
      "|02/08/13|    1|   1|   11|\n",
      "|02/09/13|    1|   1|   14|\n",
      "|02/10/13|    1|   1|   11|\n",
      "+--------+-----+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "session = SparkSession.builder.appName('bigdata').getOrCreate()\n",
    "df = session.read.csv('dataset/bigdata.csv',header=True,inferSchema= True)\n",
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9055e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## count row\n",
    "# df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdecbf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.na.drop(how='any')\n",
    "# df.count()\n",
    "# col_name = df.columns\n",
    "# col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07160c41",
   "metadata": {},
   "source": [
    "## we need to modify date field by Replace Column Value Character by Character (/ by -)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a19da",
   "metadata": {},
   "source": [
    "By using translate() string function you can replace character by character of DataFrame column value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ca9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "###very important code\n",
    "# from pyspark.sql.functions import translate\n",
    "# df = df.withColumn('date', translate('date', '/', '-'))\n",
    "# df.show(n=10)\n",
    "#This unix_timestamp support only dd-mm-yy ex (02-12-21). but our row data was some of them this format somr of them\n",
    "#10/12/2021 format. so at frist I format this to 10/12/2021 format in excel. then I replaced / by - using this line. then \n",
    "# I apply from_unixtime funsion and change to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb9f767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#seperate datetime\n",
    "# from pyspark.sql.functions import year\n",
    "# from pyspark.sql.functions import to_timestamp,date_format\n",
    "# from pyspark.sql.functions import col\n",
    "# from pyspark.sql.functions import unix_timestamp, from_unixtime\n",
    "\n",
    "# df2 = df.select(\n",
    "#     'date', 'store', 'item', 'sales', \n",
    "#     from_unixtime(unix_timestamp('date', 'dd-mm-yy')).alias('datetime')\n",
    "# )\n",
    "# df2.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a101a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3cca31",
   "metadata": {},
   "source": [
    "## Separate datetime : day ,month, year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da160b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df2.withColumn('month',month(df2.datetime)).withColumn('year',year(df2.datetime))\n",
    "# df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a102c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba54d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Easy way to retrive day\n",
    "\n",
    "# df2 = df2.select(\n",
    "#     'date', 'store', 'item', 'sales', 'datetime', 'month', 'year', \n",
    "#     dayofmonth(\"datetime\").alias('day')\n",
    "# )\n",
    "# df2.show(n=100)\n",
    "\n",
    "# final_df = df2.select(\n",
    "#     'date','datetime',\n",
    "#     year(\"datetime\").alias('year'), \n",
    "#     month(\"datetime\").alias('month'),\n",
    "#     dayofmonth(\"datetime\").alias('day'),\n",
    "#     'store', 'item', 'sales',\n",
    "# )\n",
    "# final_df.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb09430",
   "metadata": {},
   "source": [
    " ## Separate datetime : day ,month, year (effective way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac533d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initailize SparkSession and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bffe4680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date', 'store', 'item', 'sales']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.na.drop(how='any')\n",
    "df.count()\n",
    "col_name = df.columns\n",
    "col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "240b497d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+-----+\n",
      "|    date|store|item|sales|\n",
      "+--------+-----+----+-----+\n",
      "|02-01-13|    1|   1|   11|\n",
      "|02-02-13|    1|   1|   21|\n",
      "|02-03-13|    1|   1|   15|\n",
      "|02-04-13|    1|   1|   14|\n",
      "|02-05-13|    1|   1|    9|\n",
      "|02-06-13|    1|   1|   10|\n",
      "|02-07-13|    1|   1|   13|\n",
      "|02-08-13|    1|   1|   11|\n",
      "|02-09-13|    1|   1|   14|\n",
      "|02-10-13|    1|   1|   11|\n",
      "|02-11-13|    1|   1|   16|\n",
      "|02-12-13|    1|   1|   11|\n",
      "|13-02-13|    1|   1|   14|\n",
      "|14-02-13|    1|   1|   10|\n",
      "|15-02-13|    1|   1|   11|\n",
      "|16-02-13|    1|   1|    7|\n",
      "|17-02-13|    1|   1|   11|\n",
      "|18-02-13|    1|   1|   10|\n",
      "|19-02-13|    1|   1|   10|\n",
      "|20-02-13|    1|   1|    7|\n",
      "+--------+-----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###very important code\n",
    "from pyspark.sql.functions import translate,to_date,split\n",
    "final_df = df.withColumn('date', translate('date', '/', '-'))\n",
    "#This unix_timestamp support only dd-mm-yy ex (02-12-21). but our row data was some of them this format somr of them\n",
    "#10/12/2021 format. so at frist I fortamt this to 10/12/2021 format in excel. then I replaced / by - using this line. then \n",
    "# I apply from_unixtime funsion and change to \n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d37c5619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+-----+---+-----+----+\n",
      "|date    |store|item|sales|day|month|year|\n",
      "+--------+-----+----+-----+---+-----+----+\n",
      "|02-01-13|1    |1   |11   |02 |01   |13  |\n",
      "|02-02-13|1    |1   |21   |02 |02   |13  |\n",
      "|02-03-13|1    |1   |15   |02 |03   |13  |\n",
      "|02-04-13|1    |1   |14   |02 |04   |13  |\n",
      "|02-05-13|1    |1   |9    |02 |05   |13  |\n",
      "|02-06-13|1    |1   |10   |02 |06   |13  |\n",
      "|02-07-13|1    |1   |13   |02 |07   |13  |\n",
      "|02-08-13|1    |1   |11   |02 |08   |13  |\n",
      "|02-09-13|1    |1   |14   |02 |09   |13  |\n",
      "|02-10-13|1    |1   |11   |02 |10   |13  |\n",
      "|02-11-13|1    |1   |16   |02 |11   |13  |\n",
      "|02-12-13|1    |1   |11   |02 |12   |13  |\n",
      "|13-02-13|1    |1   |14   |13 |02   |13  |\n",
      "|14-02-13|1    |1   |10   |14 |02   |13  |\n",
      "|15-02-13|1    |1   |11   |15 |02   |13  |\n",
      "|16-02-13|1    |1   |7    |16 |02   |13  |\n",
      "|17-02-13|1    |1   |11   |17 |02   |13  |\n",
      "|18-02-13|1    |1   |10   |18 |02   |13  |\n",
      "|19-02-13|1    |1   |10   |19 |02   |13  |\n",
      "|20-02-13|1    |1   |7    |20 |02   |13  |\n",
      "+--------+-----+----+-----+---+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df = final_df.withColumn('day', split(final_df['date'], '-').getItem(0)).withColumn('month', split(final_df['date'], '-').getItem(1)).withColumn('year', split(final_df['date'], '-').getItem(2))\n",
    "final_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80aba191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date', 'store', 'item', 'sales', 'day', 'month', 'year']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.count()\n",
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21320650",
   "metadata": {},
   "outputs": [],
   "source": [
    "### export data to csv\n",
    "final_df = final_df.select(['date','day', 'month', 'year', 'store', 'item', 'sales'])\n",
    "final_df.toPandas().to_csv('dataset/modyfiedBigdata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9ddfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f6d03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741efb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d373b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
